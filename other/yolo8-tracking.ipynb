{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPhlPgbGrIL+2Fcw6nPxwY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Практическое занятие по методам трекинга объектов на основе модели Yolo"
      ],
      "metadata": {
        "id": "FbYbzv5wzX78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка окружения для работы с Yolo\n",
        "\n",
        "Установка пакета Ultralytics для работы с моделью Yolo."
      ],
      "metadata": {
        "id": "Bbo5vmJ8zl09"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GJlkQeGgqqw"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка весовых коэффициентов предобученной модели."
      ],
      "metadata": {
        "id": "8_zD3LPgz4s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8x.pt"
      ],
      "metadata": {
        "id": "5uGZWuOwguXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "ajFpRTb3hHqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Детекция объектов на изображении"
      ],
      "metadata": {
        "id": "GIKmULa31rmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sources.csv\n",
        "url\n",
        "https://raw.githubusercontent.com/ant-nik/neural_network_course/main/practice_2_data/video_1_fixed/image_001.jpg\n",
        "https://raw.githubusercontent.com/ant-nik/neural_network_course/main/practice_2_data/video_1_fixed/image_002.jpg\n",
        "https://raw.githubusercontent.com/ant-nik/neural_network_course/main/practice_2_data/video_1_fixed/image_003.jpg\n",
        "https://raw.githubusercontent.com/ant-nik/neural_network_course/main/practice_2_data/video_2_fixed/image_005.jpg"
      ],
      "metadata": {
        "id": "sxdPFf6tnJXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images\n",
        "!cd images && for line in `cat ../sources.csv`; do wget $line; done"
      ],
      "metadata": {
        "id": "WD6sN_7zpDWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile localfiles.csv\n",
        "images/image_001.jpg\n",
        "images/image_002.jpg\n",
        "images/image_003.jpg\n",
        "images/image_005.jpg"
      ],
      "metadata": {
        "id": "VARJmZgsnog5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import plotly.express as plte\n",
        "\n",
        "# Load a pretrained YOLOv8n model\n",
        "model = YOLO('yolov8x.pt')\n",
        "# Define remote image or video URL\n",
        "source = 'localfiles.csv'\n",
        "# Run inference on the source\n",
        "results = model(\"./images\")  # list of Results objects\n",
        "for res in results:\n",
        "    plte.imshow(res.plot()).show()"
      ],
      "metadata": {
        "id": "DOdjig7uhJSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(results[0].names[int(results[0].boxes.cls[0])], results[0].names[int(results[0].boxes.cls[1])]) #"
      ],
      "metadata": {
        "id": "T_W4nKJlzAF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Трекинг объектов"
      ],
      "metadata": {
        "id": "PGvK9KktM9HS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video = \"https://github.com/ant-nik/neural_network_course/raw/main/practice_2_data/video_1/video_1.mp4\"\n",
        "\n",
        "# Perform tracking with the model\n",
        "results = model.track(source=video, show=False)  # Tracking with default tracker"
      ],
      "metadata": {
        "id": "2k2a3DYTHQrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plte.imshow(results[5].plot())"
      ],
      "metadata": {
        "id": "gRABWiTsOOgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"{1:0>5}\".format(5, 4)"
      ],
      "metadata": {
        "id": "J3POO8xOTg9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir output\n",
        "from collections import defaultdict\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Open the video file\n",
        "# video_path = \"tracked_video.mp4\"\n",
        "# cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Store the track history\n",
        "track_history = defaultdict(lambda: [])\n",
        "\n",
        "i = 0\n",
        "for frame in results:\n",
        "    # Get the boxes and track IDs\n",
        "    boxes = frame.boxes.xywh.cpu()\n",
        "    annotated_frame = frame.plot()\n",
        "\n",
        "    if not frame.boxes.id is None:\n",
        "        track_ids = frame.boxes.id.int().cpu().tolist()\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "\n",
        "\n",
        "        # Plot the tracks\n",
        "        for box, track_id in zip(boxes, track_ids):\n",
        "            x, y, w, h = box\n",
        "            track = track_history[track_id]\n",
        "            track.append((float(x), float(y)))  # x, y center point\n",
        "            if len(track) > 30:  # retain 90 tracks for 90 frames\n",
        "                track.pop(0)\n",
        "\n",
        "            # Draw the tracking lines\n",
        "            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
        "            cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
        "\n",
        "    # Display the annotated frame\n",
        "    cv2.imwrite(\"output/image{0:0>5}.jpg\".format(i), annotated_frame)\n",
        "    i = i + 1\n",
        "# Release the video capture object and close the display window\n",
        "# cap.release()\n",
        "# cv2.destroyAllWindows()\n",
        "!ffmpeg -framerate 30 -pattern_type glob -i 'output/*.jpg' -c:v libx264 -pix_fmt yuv420p out.mp4"
      ],
      "metadata": {
        "id": "ltITLZrwRoea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame.boxes"
      ],
      "metadata": {
        "id": "nccNNy8DVDGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dHfheW_bU57k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}